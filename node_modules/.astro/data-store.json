[["Map",1,2,9,10],"meta::meta",["Map",3,4,5,6,7,8],"astro-version","5.17.1","content-config-digest","721a89bc3b6160e6","astro-config-digest","{\"root\":{},\"srcDir\":{},\"publicDir\":{},\"outDir\":{},\"cacheDir\":{},\"site\":\"https://seo.freetoolkit.cc\",\"compressHTML\":true,\"base\":\"/\",\"trailingSlash\":\"ignore\",\"output\":\"static\",\"scopedStyleStrategy\":\"attribute\",\"build\":{\"format\":\"directory\",\"client\":{},\"server\":{},\"assets\":\"_astro\",\"serverEntry\":\"entry.mjs\",\"redirects\":true,\"inlineStylesheets\":\"auto\",\"concurrency\":1},\"server\":{\"open\":false,\"host\":false,\"port\":4321,\"streaming\":true,\"allowedHosts\":[]},\"redirects\":{},\"image\":{\"endpoint\":{\"route\":\"/_image\"},\"service\":{\"entrypoint\":\"astro/assets/services/sharp\",\"config\":{}},\"domains\":[],\"remotePatterns\":[],\"responsiveStyles\":false},\"devToolbar\":{\"enabled\":true},\"markdown\":{\"syntaxHighlight\":{\"type\":\"shiki\",\"excludeLangs\":[\"math\"]},\"shikiConfig\":{\"langs\":[],\"langAlias\":{},\"theme\":\"github-dark\",\"themes\":{},\"wrap\":false,\"transformers\":[]},\"remarkPlugins\":[],\"rehypePlugins\":[],\"remarkRehype\":{},\"gfm\":true,\"smartypants\":true},\"security\":{\"checkOrigin\":true,\"allowedDomains\":[]},\"env\":{\"schema\":{},\"validateSecrets\":false},\"experimental\":{\"clientPrerender\":false,\"contentIntellisense\":false,\"headingIdCompat\":false,\"preserveScriptOrder\":false,\"liveContentCollections\":false,\"csp\":false,\"staticImportMetaEnv\":false,\"chromeDevtoolsWorkspace\":false,\"failOnPrerenderConflict\":false,\"svgo\":false},\"legacy\":{\"collections\":false}}","posts",["Map",11,12,51,52,90,91,127,128,162,163,200,201],"canonical-urls-duplicate-content",{"id":11,"data":13,"body":22,"filePath":23,"digest":24,"rendered":25,"legacyId":50},{"title":14,"description":15,"publishDate":16,"category":17,"tags":18},"Canonical URLs: Solving Duplicate Content Issues","How to use canonical URLs to prevent duplicate content penalties.","2026-02-03","Technical",[19,20,21],"canonical","duplicate-content","seo","Duplicate content occurs when the same or very similar content is accessible at multiple URLs. This dilutes your SEO value and confuses search engines about which version to index.\n\n## Common Causes of Duplicate Content\n\nURL parameters like tracking codes and session IDs create duplicate URLs. HTTP and HTTPS versions of the same page are seen as duplicates. WWW and non-WWW versions are separate URLs. Trailing slashes create different URLs. Print-friendly page versions duplicate content.\n\n## How Canonical Tags Work\n\nThe canonical tag tells search engines which URL is the preferred version. All duplicate pages should include a canonical tag pointing to the original. Search engines consolidate ranking signals to the canonical URL.\n\n## Self-Referencing Canonicals\n\nEvery page should include a canonical tag pointing to itself. This prevents issues when parameters are appended to the URL and reinforces the preferred URL format.\n\n## Implementation Tips\n\nUse absolute URLs in canonical tags, not relative. Ensure the canonical URL is accessible and returns a 200 status code. Do not canonicalize paginated content to page one. Use our Canonical URL Builder to generate correct tags.\n\n## Canonical vs Redirect\n\nUse canonical tags when you want both URLs to remain accessible. Use 301 redirects when you want to permanently move traffic from one URL to another. Redirects are stronger signals than canonical tags.","src/content/posts/canonical-urls-duplicate-content.md","8d1d8c79d60e891f",{"html":26,"metadata":27},"\u003Cp>Duplicate content occurs when the same or very similar content is accessible at multiple URLs. This dilutes your SEO value and confuses search engines about which version to index.\u003C/p>\n\u003Ch2 id=\"common-causes-of-duplicate-content\">Common Causes of Duplicate Content\u003C/h2>\n\u003Cp>URL parameters like tracking codes and session IDs create duplicate URLs. HTTP and HTTPS versions of the same page are seen as duplicates. WWW and non-WWW versions are separate URLs. Trailing slashes create different URLs. Print-friendly page versions duplicate content.\u003C/p>\n\u003Ch2 id=\"how-canonical-tags-work\">How Canonical Tags Work\u003C/h2>\n\u003Cp>The canonical tag tells search engines which URL is the preferred version. All duplicate pages should include a canonical tag pointing to the original. Search engines consolidate ranking signals to the canonical URL.\u003C/p>\n\u003Ch2 id=\"self-referencing-canonicals\">Self-Referencing Canonicals\u003C/h2>\n\u003Cp>Every page should include a canonical tag pointing to itself. This prevents issues when parameters are appended to the URL and reinforces the preferred URL format.\u003C/p>\n\u003Ch2 id=\"implementation-tips\">Implementation Tips\u003C/h2>\n\u003Cp>Use absolute URLs in canonical tags, not relative. Ensure the canonical URL is accessible and returns a 200 status code. Do not canonicalize paginated content to page one. Use our Canonical URL Builder to generate correct tags.\u003C/p>\n\u003Ch2 id=\"canonical-vs-redirect\">Canonical vs Redirect\u003C/h2>\n\u003Cp>Use canonical tags when you want both URLs to remain accessible. Use 301 redirects when you want to permanently move traffic from one URL to another. Redirects are stronger signals than canonical tags.\u003C/p>",{"headings":28,"localImagePaths":45,"remoteImagePaths":46,"frontmatter":47,"imagePaths":49},[29,33,36,39,42],{"depth":30,"slug":31,"text":32},2,"common-causes-of-duplicate-content","Common Causes of Duplicate Content",{"depth":30,"slug":34,"text":35},"how-canonical-tags-work","How Canonical Tags Work",{"depth":30,"slug":37,"text":38},"self-referencing-canonicals","Self-Referencing Canonicals",{"depth":30,"slug":40,"text":41},"implementation-tips","Implementation Tips",{"depth":30,"slug":43,"text":44},"canonical-vs-redirect","Canonical vs Redirect",[],[],{"title":14,"description":15,"publishDate":16,"category":17,"tags":48},[19,20,21],[],"canonical-urls-duplicate-content.md","keyword-density-best-practices",{"id":51,"data":53,"body":62,"filePath":63,"digest":64,"rendered":65,"legacyId":89},{"title":54,"description":55,"publishDate":56,"category":57,"tags":58},"Keyword Density: What It Is and Why It Still Matters","Understanding keyword density and how to optimize content without over-stuffing.","2026-02-01","Guide",[59,60,61],"keywords","content","optimization","Keyword density measures how often a target keyword appears relative to total word count. While search engines have evolved beyond simple keyword counting, density remains a useful diagnostic tool.\n\n## What Is Keyword Density\n\nKeyword density is calculated as: (keyword count / total words) × 100. If your keyword appears 15 times in a 1000-word article, the density is 1.5%.\n\n## Optimal Density Range\n\nThere is no perfect keyword density. However, most SEO experts suggest a primary keyword density between 1-3%. Higher densities can trigger keyword stuffing penalties. Lower densities may not signal relevance strongly enough.\n\n## Beyond Single Keywords\n\nModern SEO focuses on topic coverage rather than exact keyword repetition. Use variations, synonyms, and related terms naturally throughout your content. Search engines understand semantic relationships between words.\n\n## Using Our Keyword Density Analyzer\n\nOur tool analyzes your content and shows the frequency and density of every significant word. Look for your target keyword in the results and ensure it falls within a natural range. If a word appears too frequently, find opportunities to use synonyms instead.\n\n## Content Quality First\n\nAlways write for humans first, then optimize for search engines. Well-written content that thoroughly covers a topic will naturally include relevant keywords at appropriate densities. Forced keyword insertion makes content unreadable and can harm rankings.","src/content/posts/keyword-density-best-practices.md","f0146a997a724efc",{"html":66,"metadata":67},"\u003Cp>Keyword density measures how often a target keyword appears relative to total word count. While search engines have evolved beyond simple keyword counting, density remains a useful diagnostic tool.\u003C/p>\n\u003Ch2 id=\"what-is-keyword-density\">What Is Keyword Density\u003C/h2>\n\u003Cp>Keyword density is calculated as: (keyword count / total words) × 100. If your keyword appears 15 times in a 1000-word article, the density is 1.5%.\u003C/p>\n\u003Ch2 id=\"optimal-density-range\">Optimal Density Range\u003C/h2>\n\u003Cp>There is no perfect keyword density. However, most SEO experts suggest a primary keyword density between 1-3%. Higher densities can trigger keyword stuffing penalties. Lower densities may not signal relevance strongly enough.\u003C/p>\n\u003Ch2 id=\"beyond-single-keywords\">Beyond Single Keywords\u003C/h2>\n\u003Cp>Modern SEO focuses on topic coverage rather than exact keyword repetition. Use variations, synonyms, and related terms naturally throughout your content. Search engines understand semantic relationships between words.\u003C/p>\n\u003Ch2 id=\"using-our-keyword-density-analyzer\">Using Our Keyword Density Analyzer\u003C/h2>\n\u003Cp>Our tool analyzes your content and shows the frequency and density of every significant word. Look for your target keyword in the results and ensure it falls within a natural range. If a word appears too frequently, find opportunities to use synonyms instead.\u003C/p>\n\u003Ch2 id=\"content-quality-first\">Content Quality First\u003C/h2>\n\u003Cp>Always write for humans first, then optimize for search engines. Well-written content that thoroughly covers a topic will naturally include relevant keywords at appropriate densities. Forced keyword insertion makes content unreadable and can harm rankings.\u003C/p>",{"headings":68,"localImagePaths":84,"remoteImagePaths":85,"frontmatter":86,"imagePaths":88},[69,72,75,78,81],{"depth":30,"slug":70,"text":71},"what-is-keyword-density","What Is Keyword Density",{"depth":30,"slug":73,"text":74},"optimal-density-range","Optimal Density Range",{"depth":30,"slug":76,"text":77},"beyond-single-keywords","Beyond Single Keywords",{"depth":30,"slug":79,"text":80},"using-our-keyword-density-analyzer","Using Our Keyword Density Analyzer",{"depth":30,"slug":82,"text":83},"content-quality-first","Content Quality First",[],[],{"title":54,"description":55,"publishDate":56,"category":57,"tags":87},[59,60,61],[],"keyword-density-best-practices.md","open-graph-social-sharing",{"id":90,"data":92,"body":99,"filePath":100,"digest":101,"rendered":102,"legacyId":126},{"title":93,"description":94,"publishDate":16,"category":57,"tags":95},"Open Graph Tags: Optimize Social Media Sharing","How to use Open Graph tags to control how your content appears on social platforms.",[96,97,98],"open-graph","social","meta-tags","Open Graph protocol lets you control how your web pages appear when shared on social media platforms like Facebook, LinkedIn, and Pinterest.\n\n## Essential OG Tags\n\nEvery page should include: og:title (the content title), og:description (a brief summary), og:image (the preview image), og:url (the canonical URL), and og:type (usually website or article).\n\n## Image Requirements\n\nFacebook recommends 1200x630 pixels for optimal display. Images must be at least 200x200 pixels. Keep important content centered since different platforms crop differently. Use high-quality images that represent your content well.\n\n## Testing Your Tags\n\nUse our Open Graph Preview tool to see how your page will appear before publishing. Facebook also provides a sharing debugger that shows exactly how their crawler sees your page.\n\n## Common Mistakes\n\nUsing the same image for every page reduces click-through rates. Missing og:image means platforms will pick a random image from your page. Descriptions that are too long get truncated. Not updating tags after content changes leads to outdated previews.\n\n## Platform-Specific Notes\n\nLinkedIn uses OG tags and also supports its own meta tags. Pinterest uses OG tags and also reads Schema.org markup. Twitter primarily uses its own Twitter Card tags but falls back to OG tags if Twitter-specific tags are missing.","src/content/posts/open-graph-social-sharing.md","8009938140c52667",{"html":103,"metadata":104},"\u003Cp>Open Graph protocol lets you control how your web pages appear when shared on social media platforms like Facebook, LinkedIn, and Pinterest.\u003C/p>\n\u003Ch2 id=\"essential-og-tags\">Essential OG Tags\u003C/h2>\n\u003Cp>Every page should include: og:title (the content title), og:description (a brief summary), og:image (the preview image), og:url (the canonical URL), and og:type (usually website or article).\u003C/p>\n\u003Ch2 id=\"image-requirements\">Image Requirements\u003C/h2>\n\u003Cp>Facebook recommends 1200x630 pixels for optimal display. Images must be at least 200x200 pixels. Keep important content centered since different platforms crop differently. Use high-quality images that represent your content well.\u003C/p>\n\u003Ch2 id=\"testing-your-tags\">Testing Your Tags\u003C/h2>\n\u003Cp>Use our Open Graph Preview tool to see how your page will appear before publishing. Facebook also provides a sharing debugger that shows exactly how their crawler sees your page.\u003C/p>\n\u003Ch2 id=\"common-mistakes\">Common Mistakes\u003C/h2>\n\u003Cp>Using the same image for every page reduces click-through rates. Missing og:image means platforms will pick a random image from your page. Descriptions that are too long get truncated. Not updating tags after content changes leads to outdated previews.\u003C/p>\n\u003Ch2 id=\"platform-specific-notes\">Platform-Specific Notes\u003C/h2>\n\u003Cp>LinkedIn uses OG tags and also supports its own meta tags. Pinterest uses OG tags and also reads Schema.org markup. Twitter primarily uses its own Twitter Card tags but falls back to OG tags if Twitter-specific tags are missing.\u003C/p>",{"headings":105,"localImagePaths":121,"remoteImagePaths":122,"frontmatter":123,"imagePaths":125},[106,109,112,115,118],{"depth":30,"slug":107,"text":108},"essential-og-tags","Essential OG Tags",{"depth":30,"slug":110,"text":111},"image-requirements","Image Requirements",{"depth":30,"slug":113,"text":114},"testing-your-tags","Testing Your Tags",{"depth":30,"slug":116,"text":117},"common-mistakes","Common Mistakes",{"depth":30,"slug":119,"text":120},"platform-specific-notes","Platform-Specific Notes",[],[],{"title":93,"description":94,"publishDate":16,"category":57,"tags":124},[96,97,98],[],"open-graph-social-sharing.md","seo-meta-tags-guide",{"id":127,"data":129,"body":134,"filePath":135,"digest":136,"rendered":137,"legacyId":161},{"title":130,"description":131,"publishDate":56,"category":57,"tags":132},"SEO Meta Tags: The Complete Guide for 2026","How to write effective meta tags that improve search rankings and click-through rates.",[98,21,133],"html","Meta tags tell search engines about your page content. While not all meta tags affect rankings directly, they play a crucial role in how your pages appear in search results.\n\n## Title Tag\n\nThe title tag is the most important on-page SEO element. It appears as the clickable headline in search results. Keep titles between 30-60 characters. Include your primary keyword near the beginning. Make each title unique across your site. Our Title Checker helps you optimize length and preview appearance.\n\n## Meta Description\n\nThe meta description appears below the title in search results. While not a direct ranking factor, a compelling description improves click-through rate. Keep descriptions between 120-160 characters. Include a call to action. Use your target keyword naturally.\n\n## Open Graph Tags\n\nOpen Graph tags control how your page appears when shared on Facebook, LinkedIn, and other platforms. Include og:title, og:description, og:image, and og:url at minimum. Use our OG Preview tool to see exactly how your page will look when shared.\n\n## Twitter Cards\n\nTwitter Card tags work similarly to Open Graph but are specific to Twitter. Choose between summary and summary_large_image card types. Large image cards tend to get more engagement.\n\n## Canonical Tags\n\nCanonical tags prevent duplicate content issues by telling search engines which version of a page is the original. Use our Canonical URL Builder to generate the correct tags for your pages.","src/content/posts/seo-meta-tags-guide.md","2d0a670669d9aa22",{"html":138,"metadata":139},"\u003Cp>Meta tags tell search engines about your page content. While not all meta tags affect rankings directly, they play a crucial role in how your pages appear in search results.\u003C/p>\n\u003Ch2 id=\"title-tag\">Title Tag\u003C/h2>\n\u003Cp>The title tag is the most important on-page SEO element. It appears as the clickable headline in search results. Keep titles between 30-60 characters. Include your primary keyword near the beginning. Make each title unique across your site. Our Title Checker helps you optimize length and preview appearance.\u003C/p>\n\u003Ch2 id=\"meta-description\">Meta Description\u003C/h2>\n\u003Cp>The meta description appears below the title in search results. While not a direct ranking factor, a compelling description improves click-through rate. Keep descriptions between 120-160 characters. Include a call to action. Use your target keyword naturally.\u003C/p>\n\u003Ch2 id=\"open-graph-tags\">Open Graph Tags\u003C/h2>\n\u003Cp>Open Graph tags control how your page appears when shared on Facebook, LinkedIn, and other platforms. Include og:title, og:description, og:image, and og:url at minimum. Use our OG Preview tool to see exactly how your page will look when shared.\u003C/p>\n\u003Ch2 id=\"twitter-cards\">Twitter Cards\u003C/h2>\n\u003Cp>Twitter Card tags work similarly to Open Graph but are specific to Twitter. Choose between summary and summary_large_image card types. Large image cards tend to get more engagement.\u003C/p>\n\u003Ch2 id=\"canonical-tags\">Canonical Tags\u003C/h2>\n\u003Cp>Canonical tags prevent duplicate content issues by telling search engines which version of a page is the original. Use our Canonical URL Builder to generate the correct tags for your pages.\u003C/p>",{"headings":140,"localImagePaths":156,"remoteImagePaths":157,"frontmatter":158,"imagePaths":160},[141,144,147,150,153],{"depth":30,"slug":142,"text":143},"title-tag","Title Tag",{"depth":30,"slug":145,"text":146},"meta-description","Meta Description",{"depth":30,"slug":148,"text":149},"open-graph-tags","Open Graph Tags",{"depth":30,"slug":151,"text":152},"twitter-cards","Twitter Cards",{"depth":30,"slug":154,"text":155},"canonical-tags","Canonical Tags",[],[],{"title":130,"description":131,"publishDate":56,"category":57,"tags":159},[98,21,133],[],"seo-meta-tags-guide.md","xml-sitemap-best-practices",{"id":162,"data":164,"body":172,"filePath":173,"digest":174,"rendered":175,"legacyId":199},{"title":165,"description":166,"publishDate":167,"category":17,"tags":168},"XML Sitemaps: Best Practices for SEO","How to create and maintain XML sitemaps for better search engine indexing.","2026-02-02",[169,170,171],"sitemap","xml","indexing","XML sitemaps help search engines discover and index your pages more efficiently. They list all important URLs on your site along with metadata about each page.\n\n## Why Sitemaps Matter\n\nSitemaps are especially important for large sites, new sites with few external links, sites with pages not well linked internally, and sites that change content frequently. They help search engines find pages that might be missed during regular crawling.\n\n## Sitemap Structure\n\nEach URL entry can include: loc (the URL, required), lastmod (last modification date), changefreq (how often the page changes), and priority (relative importance from 0.0 to 1.0).\n\n## Priority and Changefreq\n\nPriority tells search engines which pages are most important relative to other pages on your site. Set your homepage and key landing pages to 0.8-1.0. Set blog posts to 0.6-0.7. Set archive pages to 0.3-0.4. Changefreq should honestly reflect how often content actually changes.\n\n## Sitemap Limits\n\nA single sitemap can contain up to 50,000 URLs and must not exceed 50MB uncompressed. For larger sites, use a sitemap index file that references multiple sitemaps.\n\n## Submitting Your Sitemap\n\nSubmit your sitemap through Google Search Console and Bing Webmaster Tools. Also reference it in your robots.txt file. Our Sitemap Generator creates properly formatted XML sitemaps from your URL list.","src/content/posts/xml-sitemap-best-practices.md","05a6cca2bd8c60e5",{"html":176,"metadata":177},"\u003Cp>XML sitemaps help search engines discover and index your pages more efficiently. They list all important URLs on your site along with metadata about each page.\u003C/p>\n\u003Ch2 id=\"why-sitemaps-matter\">Why Sitemaps Matter\u003C/h2>\n\u003Cp>Sitemaps are especially important for large sites, new sites with few external links, sites with pages not well linked internally, and sites that change content frequently. They help search engines find pages that might be missed during regular crawling.\u003C/p>\n\u003Ch2 id=\"sitemap-structure\">Sitemap Structure\u003C/h2>\n\u003Cp>Each URL entry can include: loc (the URL, required), lastmod (last modification date), changefreq (how often the page changes), and priority (relative importance from 0.0 to 1.0).\u003C/p>\n\u003Ch2 id=\"priority-and-changefreq\">Priority and Changefreq\u003C/h2>\n\u003Cp>Priority tells search engines which pages are most important relative to other pages on your site. Set your homepage and key landing pages to 0.8-1.0. Set blog posts to 0.6-0.7. Set archive pages to 0.3-0.4. Changefreq should honestly reflect how often content actually changes.\u003C/p>\n\u003Ch2 id=\"sitemap-limits\">Sitemap Limits\u003C/h2>\n\u003Cp>A single sitemap can contain up to 50,000 URLs and must not exceed 50MB uncompressed. For larger sites, use a sitemap index file that references multiple sitemaps.\u003C/p>\n\u003Ch2 id=\"submitting-your-sitemap\">Submitting Your Sitemap\u003C/h2>\n\u003Cp>Submit your sitemap through Google Search Console and Bing Webmaster Tools. Also reference it in your robots.txt file. Our Sitemap Generator creates properly formatted XML sitemaps from your URL list.\u003C/p>",{"headings":178,"localImagePaths":194,"remoteImagePaths":195,"frontmatter":196,"imagePaths":198},[179,182,185,188,191],{"depth":30,"slug":180,"text":181},"why-sitemaps-matter","Why Sitemaps Matter",{"depth":30,"slug":183,"text":184},"sitemap-structure","Sitemap Structure",{"depth":30,"slug":186,"text":187},"priority-and-changefreq","Priority and Changefreq",{"depth":30,"slug":189,"text":190},"sitemap-limits","Sitemap Limits",{"depth":30,"slug":192,"text":193},"submitting-your-sitemap","Submitting Your Sitemap",[],[],{"title":165,"description":166,"publishDate":167,"category":17,"tags":197},[169,170,171],[],"xml-sitemap-best-practices.md","robots-txt-complete-guide",{"id":200,"data":202,"body":209,"filePath":210,"digest":211,"rendered":212,"legacyId":236},{"title":203,"description":204,"publishDate":167,"category":17,"tags":205},"Robots.txt: Complete Guide for Search Engine Crawling","How to create and configure robots.txt for optimal search engine crawling.",[206,207,208],"robots-txt","crawling","technical-seo","The robots.txt file tells search engine crawlers which pages they can and cannot access on your site. It is one of the first files crawlers look for when visiting a website.\n\n## How Robots.txt Works\n\nThe file must be placed at the root of your domain (example.com/robots.txt). Crawlers read it before accessing any other page. Rules specify which user agents (crawlers) can access which paths.\n\n## Basic Syntax\n\nUser-agent specifies which crawler the rules apply to. Use * for all crawlers. Disallow prevents crawlers from accessing specified paths. Allow explicitly permits access to paths within a disallowed directory.\n\n## Common Configurations\n\nBlock all crawlers from a directory: Disallow /admin/. Allow a specific page in a blocked directory: Allow /admin/public. Block a specific crawler: User-agent: BadBot followed by Disallow /.\n\n## Important Considerations\n\nRobots.txt is a suggestion, not a security measure. Malicious bots may ignore it. Do not use it to hide sensitive information. Blocking CSS and JavaScript can hurt SEO because search engines need these to render your pages.\n\n## Sitemap Reference\n\nAlways include a Sitemap directive pointing to your XML sitemap. This helps crawlers discover all your pages efficiently. Use our Robots.txt Generator to create properly formatted files.","src/content/posts/robots-txt-complete-guide.md","42fe2bd298577609",{"html":213,"metadata":214},"\u003Cp>The robots.txt file tells search engine crawlers which pages they can and cannot access on your site. It is one of the first files crawlers look for when visiting a website.\u003C/p>\n\u003Ch2 id=\"how-robotstxt-works\">How Robots.txt Works\u003C/h2>\n\u003Cp>The file must be placed at the root of your domain (example.com/robots.txt). Crawlers read it before accessing any other page. Rules specify which user agents (crawlers) can access which paths.\u003C/p>\n\u003Ch2 id=\"basic-syntax\">Basic Syntax\u003C/h2>\n\u003Cp>User-agent specifies which crawler the rules apply to. Use * for all crawlers. Disallow prevents crawlers from accessing specified paths. Allow explicitly permits access to paths within a disallowed directory.\u003C/p>\n\u003Ch2 id=\"common-configurations\">Common Configurations\u003C/h2>\n\u003Cp>Block all crawlers from a directory: Disallow /admin/. Allow a specific page in a blocked directory: Allow /admin/public. Block a specific crawler: User-agent: BadBot followed by Disallow /.\u003C/p>\n\u003Ch2 id=\"important-considerations\">Important Considerations\u003C/h2>\n\u003Cp>Robots.txt is a suggestion, not a security measure. Malicious bots may ignore it. Do not use it to hide sensitive information. Blocking CSS and JavaScript can hurt SEO because search engines need these to render your pages.\u003C/p>\n\u003Ch2 id=\"sitemap-reference\">Sitemap Reference\u003C/h2>\n\u003Cp>Always include a Sitemap directive pointing to your XML sitemap. This helps crawlers discover all your pages efficiently. Use our Robots.txt Generator to create properly formatted files.\u003C/p>",{"headings":215,"localImagePaths":231,"remoteImagePaths":232,"frontmatter":233,"imagePaths":235},[216,219,222,225,228],{"depth":30,"slug":217,"text":218},"how-robotstxt-works","How Robots.txt Works",{"depth":30,"slug":220,"text":221},"basic-syntax","Basic Syntax",{"depth":30,"slug":223,"text":224},"common-configurations","Common Configurations",{"depth":30,"slug":226,"text":227},"important-considerations","Important Considerations",{"depth":30,"slug":229,"text":230},"sitemap-reference","Sitemap Reference",[],[],{"title":203,"description":204,"publishDate":167,"category":17,"tags":234},[206,207,208],[],"robots-txt-complete-guide.md"]